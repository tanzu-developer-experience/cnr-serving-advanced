**Deploy and access workloads quickly.** A developer using Cloud Native Runtimes for Tanzu can quickly get a container deployed, a service created, and a URL to access that workload on top of Kubernetes. There is no need to configure or make decisions about nodeports, clusterIPs, or load balancers to access the running app. Cloud Native Runtimes for Tanzu can also deploy multiple containers together if, for example, a workload needs a sidecar to run alongside the application container.

**Automatically scale workloads to meet demand.** Many Kubernetes workloads do not need to be continuously running when they are not being used. One of the most important aspects of serverless technology is its ability to efficiently scale application workloads to meet demand or turn them off completely when they are not being used. Cloud Native Runtimes for Tanzu enables developers to automatically scale the number of running pods to meet incoming traffic, which includes the ability to “scale-to-zero” when there is no incoming traffic.

**Split traffic across multiple workload versions.** A huge strength of cloud native application architectures deployed on Kubernetes is the ability to orchestrate modern application upgrade patterns like Canary and blue/green deployments. Cloud Native Runtimes for Tanzu gives developers the flexibility to deploy new versions of their applications and choose how much, if any, traffic will be routed to those new versions and on what schedule. Developers can also create subroutes and tag workload versions to only be invokable by the subroute and not the main route.

